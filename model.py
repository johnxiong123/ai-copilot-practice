# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vn_AQbr8WZLIdqxV6gndrtKJqlsLewI1
"""

import tensorflow as tf
from tensorflow.keras import layers, models
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Load data
data = pd.read_csv('/home/dev/ai-copilot-practice/data.csv')

data = data.drop('date', axis=1)
data = data.drop('street', axis=1)
data = data.drop('statezip', axis=1)
data = pd.get_dummies(data, columns=['city', 'country'])

# Separate features and target
X = data.drop('price', axis=1)
y = data['price']


# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()

numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns

X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.fit_transform(X_test[numeric_cols])

X_train = np.array(X_train, dtype=np.float32)

# Build the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)  # Output layer
])

# Compile the model
model.compile(optimizer='adam',
              loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_split=0.1)

model.save('my_trained_model.h5')